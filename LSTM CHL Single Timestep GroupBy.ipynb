{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Time Series Forecasting with LSTMs in Keras\n",
    "#### Reference: https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train On Single Lag Timestep - Avg meters for 5 given area groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate, savetxt, unique, array\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv, DataFrame, concat\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataset = read_csv('CharlestownAllGroupBy.csv', header=0, sep='[,]', parse_dates=True, squeeze=True, dayfirst=True, engine='python') \n",
    "#print(dataset.head())\n",
    "dataset.drop(dataset.columns[[0,2]], axis = 1, inplace = True)\n",
    "dataset = dataset[['kWh', 'Temp', 'Area_m2', 'Month', 'Weekday', 'Holiday']]\n",
    "values = dataset.values\n",
    "#print(dataset.head())\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "#savetxt('CharlestownValues.csv', values, delimiter=',')\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, 1, 1)\n",
    "#reframed.dtypes\n",
    "# drop columns we don't want to predict\n",
    "reframed.drop(reframed.columns[[7,8,9,10,11]], axis=1, inplace=True)\n",
    "#print(reframed.head())\n",
    "#shuffle rows\n",
    "reframed=reframed.sample(frac=1).reset_index(drop=True)\n",
    "#print(reframed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "n_train_periods = int(len(values)*0.8)\n",
    "train = values[:n_train_periods, :]\n",
    "test = values[n_train_periods:, :]\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "#print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1316 samples, validate on 329 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.1679 - val_loss: 0.1500\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.1285 - val_loss: 0.1172\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.1018 - val_loss: 0.0886\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.0726 - val_loss: 0.0600\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.0489 - val_loss: 0.0432\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.0371 - val_loss: 0.0391\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.0350 - val_loss: 0.0371\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.0331 - val_loss: 0.0351\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.0317 - val_loss: 0.0345\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.0315 - val_loss: 0.0334\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.0307 - val_loss: 0.0327\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.0305 - val_loss: 0.0325\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.0304 - val_loss: 0.0320\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.0301 - val_loss: 0.0323\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.0301 - val_loss: 0.0319\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.0301 - val_loss: 0.0319\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.0301 - val_loss: 0.0318\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.0300 - val_loss: 0.0314\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.0299 - val_loss: 0.0318\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.0298 - val_loss: 0.0315\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.0299 - val_loss: 0.0314\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.0297 - val_loss: 0.0314\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.0298 - val_loss: 0.0314\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.0296 - val_loss: 0.0313\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.0295 - val_loss: 0.0315\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.0295 - val_loss: 0.0312\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.0294 - val_loss: 0.0311\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.0294 - val_loss: 0.0311\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.0294 - val_loss: 0.0313\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.0295 - val_loss: 0.0311\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.0294 - val_loss: 0.0314\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.0295 - val_loss: 0.0307\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.0292 - val_loss: 0.0311\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.0293 - val_loss: 0.0310\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.0293 - val_loss: 0.0309\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.0292 - val_loss: 0.0309\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.0292 - val_loss: 0.0309\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.0292 - val_loss: 0.0309\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.0292 - val_loss: 0.0306\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.0290 - val_loss: 0.0305\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.0289 - val_loss: 0.0305\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.0289 - val_loss: 0.0304\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.0289 - val_loss: 0.0307\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.0290 - val_loss: 0.0308\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.0292 - val_loss: 0.0308\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.0292 - val_loss: 0.0309\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.0294 - val_loss: 0.0304\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.0290 - val_loss: 0.0306\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.0290 - val_loss: 0.0308\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.0292 - val_loss: 0.0302\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.0290 - val_loss: 0.0301\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.0289 - val_loss: 0.0303\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.0291 - val_loss: 0.0301\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.0288 - val_loss: 0.0303\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.0289 - val_loss: 0.0300\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.0291 - val_loss: 0.0299\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.0284 - val_loss: 0.0303\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.0286 - val_loss: 0.0302\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.0286 - val_loss: 0.0301\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.0288 - val_loss: 0.0301\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.0288 - val_loss: 0.0300\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.0290 - val_loss: 0.0298\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.0284 - val_loss: 0.0301\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.0286 - val_loss: 0.0301\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.0288 - val_loss: 0.0300\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.0291 - val_loss: 0.0298\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.0285 - val_loss: 0.0300\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.0285 - val_loss: 0.0301\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.0288 - val_loss: 0.0298\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.0287 - val_loss: 0.0299\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.0286 - val_loss: 0.0298\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.0287 - val_loss: 0.0298\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.0285 - val_loss: 0.0299\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.0285 - val_loss: 0.0300\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.0291 - val_loss: 0.0299\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.0285 - val_loss: 0.0298\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.0282 - val_loss: 0.0301\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.0286 - val_loss: 0.0297\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.0285 - val_loss: 0.0298\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.0282 - val_loss: 0.0300\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.0286 - val_loss: 0.0297\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.0288 - val_loss: 0.0297\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.0283 - val_loss: 0.0298\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.0284 - val_loss: 0.0298\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.0285 - val_loss: 0.0296\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.0283 - val_loss: 0.0298\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.0284 - val_loss: 0.0297\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.0285 - val_loss: 0.0297\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.0286 - val_loss: 0.0296\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.0284 - val_loss: 0.0297\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.0282 - val_loss: 0.0298\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.0283 - val_loss: 0.0297\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.0284 - val_loss: 0.0297\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.0282 - val_loss: 0.0300\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.0288 - val_loss: 0.0297\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.0284 - val_loss: 0.0298\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.0281 - val_loss: 0.0298\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.0282 - val_loss: 0.0297\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.0284 - val_loss: 0.0296\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.0282 - val_loss: 0.0298\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x26ebd6427c8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de7hcdX3v8fd37jP7fst1BxIqWKIgYkCtlnpplWgL2oJF61M99Rzs0+NzbCtWeM4pVvr0VHtRe0FbrFRbjlpEbWmNFUXUPq2XBEQkBEy4SDYJyc6+z577zPf8sdZONpsdMkn2zg5rfV7PM09m1qw1812zdj7rt35rzW/M3RERkehKrHQBIiKyvBT0IiIRp6AXEYk4Bb2ISMQp6EVEIi610gUsNDg46Bs3blzpMkREnlXuvvvuQ+4+tNhzp13Qb9y4kR07dqx0GSIizypm9pOjPaeuGxGRiFPQi4hEnIJeRCTiTrs+ehGRE1Gv1xkZGaFSqax0Kcsql8sxPDxMOp1uexkFvYhEwsjICF1dXWzcuBEzW+lyloW7MzY2xsjICJs2bWp7OXXdiEgkVCoVBgYGIhvyAGbGwMDAcR+1KOhFJDKiHPJzTmQdIxP0M5U6H/naj7l37+RKlyIiclqJTNA3W85f3LmbHzw+sdKliEgMTU5O8rGPfey4l3vd617H5OTyNlAjE/Qd2eC88kylscKViEgcHS3om83mMy63bds2ent7l6ssIEJX3aSTCXLpBMWqgl5ETr1rr72Whx9+mAsuuIB0Ok1nZydr167l3nvv5YEHHuANb3gDe/fupVKp8O53v5urr74aODLsS7FYZOvWrbz85S/nv/7rv1i/fj3/8i//Qj6fP+naIhP0AJ3ZtFr0IsIH/nUnD+ybXtLX3Lyum/f/0vOO+vwHP/hB7r//fu69916++c1v8vrXv57777//8GWQN998M/39/ZTLZS666CJ+5Vd+hYGBgae8xu7du/nsZz/LJz7xCd70pjfxhS98gbe+9a0nXXukgr47l1KLXkROCxdffPFTrnX/y7/8S770pS8BsHfvXnbv3v20oN+0aRMXXHABAC960Yt47LHHlqSWSAV9Zy5FsVJf6TJEZIU9U8v7VOno6Dh8/5vf/CZf//rX+c53vkOhUOAVr3jFotfCZ7PZw/eTySTlcnlJaonMyViAzqxa9CKyMrq6upiZmVn0uampKfr6+igUCjz44IN897vfPaW1RatFn03x+HhppcsQkRgaGBjgZS97Gc9//vPJ5/OsXr368HOXXnopf/M3f8P555/Pc5/7XF7ykpec0traCnozuxT4CyAJ/J27f3DB85cAHwXOB65y99vmPXcG8HfABsCB17n7Y0tS/QKduZROxorIivnMZz6z6PRsNstXvvKVRZ+b64cfHBzk/vvvPzz9mmuuWbK6jtl1Y2ZJ4EZgK7AZeLOZbV4w2+PA24HF1vIfgD9193OBi4GDJ1PwM+lS142IyNO006K/GNjj7o8AmNnngMuBB+ZmmGuhm1lr/oLhDiHl7l8L5ysuTdmL6wyvunH3WIx5ISLSjnZOxq4H9s57PBJOa8c5wKSZfdHMfmBmfxoeITyFmV1tZjvMbMfo6GibL/10Xbk0zZZTqbeOPbOISEy0E/SLNY29zddPAT8LXANcBJxF0MXz1Bdzv8ndt7j7lqGhRX/EvC2dc8MgVHWJpYjInHaCfoTgROqcYWBfm68/AvzA3R9x9wbwz8CFx1di+7pyQdAXdUJWROSwdoJ+O3C2mW0yswxwFXB7m6+/Hegzs7lm+quY17e/1OZa9DohKyJyxDGDPmyJvwv4KrALuNXdd5rZDWZ2GYCZXWRmI8CVwN+a2c5w2SZBt82dZvYjgm6gTyzPqszrulGLXkROsRMdphjgox/9KKXS8n0HqK1vxrr7Nnc/x91/yt3/KJx2vbvfHt7f7u7D7t7h7gPu/rx5y37N3c939/Pc/e3uXlueVQmuugEFvYiceqdz0Efqm7Fd2eBX0dV1IyKn2vxhin/hF36BVatWceutt1KtVnnjG9/IBz7wAWZnZ3nTm97EyMgIzWaT3//93+fAgQPs27ePV77ylQwODnLXXXcteW3RCvrDJ2N11Y1IrH3lWnjyR0v7mmvOg60fPOrT84cpvuOOO7jtttv4/ve/j7tz2WWX8e1vf5vR0VHWrVvHl7/8ZSAYA6enp4cPf/jD3HXXXQwODi5tzaFIDWrWoZOxInIauOOOO7jjjjt44QtfyIUXXsiDDz7I7t27Oe+88/j617/O+973Pv7jP/6Dnp6eU1JPpFr0mVSCbCrBjIJeJN6eoeV9Krg71113He985zuf9tzdd9/Ntm3buO6663jNa17D9ddfv+z1RKpFD0H3ja6jF5FTbf4wxa997Wu5+eabKRaDUV+eeOIJDh48yL59+ygUCrz1rW/lmmuu4Z577nnassshUi16CC6x1FU3InKqzR+meOvWrbzlLW/hpS99KQCdnZ3ccsst7Nmzh/e+970kEgnS6TQf//jHAbj66qvZunUra9euXZaTsebe7mgGp8aWLVt8x44dJ7z8L/7Vf7CqK8fNb79oCasSkdPdrl27OPfcc1e6jFNisXU1s7vdfcti80enRd+owf4fsiE1xVglOqslInKyotNHX5mET/48L298VydjRUTmiU7Q53oB6EuUKGr0SpFYOt26opfDiaxjdII+lYF0gR5mddWNSAzlcjnGxsYiHfbuztjYGLlc7riWi1Zndq6XLor6lSmRGBoeHmZkZIST+fGiZ4NcLsfw8PBxLROtoM/30tkqUm861UaLXPppP2YlIhGVTqfZtGnTSpdxWopO1w1ArpdCM/iCgq6lFxEJRCvo873km9OAxrsREZkTraDP9ZJpBF8j1glZEZFAtII+30umFrTo9QPhIiKBaAV9rpdkY5YUDbXoRURC0Qr6fPClqW5K6qMXEQm1FfRmdqmZPWRme8zs2kWev8TM7jGzhpldscjz3Wb2hJn99VIUfVTht2N7bFZX3YiIhI4Z9GaWBG4EtgKbgTeb2eYFsz0OvB34zFFe5g+Bb514mW0KW/Q9zKpFLyISaqdFfzGwx90fcfca8Dng8vkzuPtj7n4f0Fq4sJm9CFgN3LEE9T6zsEU/kCypRS8iEmon6NcDe+c9HgmnHZOZJYA/B957/KWdgLBFvypd0cBmIiKhdoJ+sQFj2h016LeAbe6+95lmMrOrzWyHme04qXEqcnNBX9JVNyIioXbGuhkBNsx7PAzsa/P1Xwr8rJn9FtAJZMys6O5POaHr7jcBN0HwC1NtvvbT5ee6bsrsVB+9iAjQXtBvB842s03AE8BVwFvaeXF3/7W5+2b2dmDLwpBfUqkspPL0JdRHLyIy55hdN+7eAN4FfBXYBdzq7jvN7AYzuwzAzC4ysxHgSuBvzWznchb9jPK99OryShGRw9oaptjdtwHbFky7ft797QRdOs/0Gp8CPnXcFR6vXC/dZV1eKSIyJ1rfjAXIH/nxERERiWLQ53rpaBV11Y2ISCh6QZ/vpdCcodZsUW00V7oaEZEVF72gz/WS1Zj0IiKHRS/o871kmrMkaaqfXkSEKAZ9bm6oYl1iKSICUQz6vIYqFhGZL3pBn9NQxSIi80Uv6Oe16DWCpYhIFIN+foteXTciIhEM+nkt+mkFvYhIBIM+bNH3J0pMldV1IyISvaBP5yCVY3WmwlixttLViIisuOgFPUCul8FUmfHZ6kpXIiKy4qIZ9Ple+hMlxkvquhERiWbQ53rpsVm16EVEiGrQ53vp8iLj6qMXEYlo0Idj0s/WmlTqGqpYROItmkGf7yXXDIYqHp9Vq15E4i2aQZ/rJdMokqCloBeR2Gsr6M3sUjN7yMz2mNm1izx/iZndY2YNM7ti3vQLzOw7ZrbTzO4zs19dyuKPKn9kqOIxBb2IxNwxg97MksCNwFZgM/BmM9u8YLbHgbcDn1kwvQT8urs/D7gU+KiZ9Z5s0ceUOzIMwoSCXkRiLtXGPBcDe9z9EQAz+xxwOfDA3Azu/lj4XGv+gu7+43n395nZQWAImDzpyp9J/sjAZmrRi0jctdN1sx7YO+/xSDjtuJjZxUAGeHiR5642sx1mtmN0dPR4X/rpwhZ9X6Kka+lFJPbaCXpbZJofz5uY2VrgH4H/5u6thc+7+03uvsXdtwwNDR3PSy8ubNGvy1Z1MlZEYq+doB8BNsx7PAzsa/cNzKwb+DLwf9z9u8dX3gkKW/RrNbCZiEhbQb8dONvMNplZBrgKuL2dFw/n/xLwD+7++RMv8ziFLfqhdEktehGJvWMGvbs3gHcBXwV2Abe6+04zu8HMLgMws4vMbAS4EvhbM9sZLv4m4BLg7WZ2b3i7YFnWZL50HlJ5hpJlxksKehGJt3auusHdtwHbFky7ft797QRdOguXuwW45SRrPDGFfvoTM4xPK+hFJN6i+c1YgEI/PT7DZKlOo/m0878iIrER3aDP99Pl0wBMaFx6EYmx6AZ9YYBCYwrQwGYiEm8RDvp+srXgC7hj+tKUiMRYdIM+30+qNqURLEUk9qIb9IUBDKeHogY2E5FYi3DQ9wPQZ0UNbCYisRb5oN+QLavrRkRiLbpBnw+DPldWi15EYi26QV8YAGBdpsS4BjYTkRiLcNAHLfqhlAY2E5F4i27QZzohmWEoUdTAZiISa9ENejPI99NvweWV7sf1WykiIpER3aAHKAzQzQyNljNdbqx0NSIiKyLiQd9PZzMY70bDIIhIXEU+6PMa2ExEYi7aQZ+fP7CZgl5E4inaQV8YIFmdxGhpvBsRia2IB30/5k26KKlFLyKx1VbQm9mlZvaQme0xs2sXef4SM7vHzBpmdsWC595mZrvD29uWqvC2HP52rMa7EZH4OmbQm1kSuBHYCmwG3mxmmxfM9jjwduAzC5btB94PvBi4GHi/mfWdfNltCse7OSNXVteNiMRWOy36i4E97v6Iu9eAzwGXz5/B3R9z9/uAhb/C/Vrga+4+7u4TwNeAS5eg7vbMa9FP6NuxIhJT7QT9emDvvMcj4bR2tLWsmV1tZjvMbMfo6GibL92GQnDwsDY9qx8IF5HYaifobZFp7Y4n0Nay7n6Tu29x9y1DQ0NtvnQb8kcGNptUi15EYqqdoB8BNsx7PAzsa/P1T2bZk5frAUsymJhRi15EYqudoN8OnG1mm8wsA1wF3N7m638VeI2Z9YUnYV8TTjs1zKDQTy9Fpit1mi0NbCYi8XPMoHf3BvAugoDeBdzq7jvN7AYzuwzAzC4ysxHgSuBvzWxnuOw48IcEO4vtwA3htFOnMEC3T+MOU2W16kUkflLtzOTu24BtC6ZdP+/+doJumcWWvRm4+SRqPDn5fjpnpwGYKNXo78isWCkiIish2t+MhXBgs2C8G52QFZE4ikXQZ8KBzSZm1XUjIvETg6AfIFWdAFxfmhKRWIp+0Of7sVaDTspM6hJLEYmh6Ad9OAzCUKKoFr2IxFIMgj74duyGfEVfmhKRWIpB0Act+vVZjWApIvEU/aAPx7tZmy6p60ZEYin6QR923axKzepkrIjEUvSDPtcLlmAoMasWvYjEUvSDPpGAfB99Ns1kqY67BjYTkXiJftAD5Pvp8SK1ZotSrbnS1YiInFLxCPpCP52tIwObiYjESUyCfoDC4YHNdEJWROIlHkGf7ydbnwLUoheR+IlH0Bf65w1spha9iMRLbII+0aySp6ox6UUkduIR9OG3Y/soakx6EYmdeAR9ON7NcFbDIIhI/LQV9GZ2qZk9ZGZ7zOzaRZ7Pmtk/hc9/z8w2htPTZvZpM/uRme0ys+uWtvw2hcMgrM+V1XUjIrFzzKA3syRwI7AV2Ay82cw2L5jtHcCEuz8H+AjwoXD6lUDW3c8DXgS8c24ncEqFLfp1mTLjOhkrIjHTTov+YmCPuz/i7jXgc8DlC+a5HPh0eP824NVmZoADHWaWAvJADZheksqPR9hHvzo1qxa9iMROO0G/Htg77/FIOG3Redy9AUwBAwShPwvsBx4H/szdxxe+gZldbWY7zGzH6Ojoca/EMeX7ABhKamAzEYmfdoLeFpm2cGSwo81zMdAE1gGbgPeY2VlPm9H9Jnff4u5bhoaG2ijpOCVTkOuh34pM6qobEYmZdoJ+BNgw7/EwsO9o84TdND3AOPAW4N/dve7uB4H/BLacbNEnJN9PLzPMVBvUm60VKUFEZCW0E/TbgbPNbJOZZYCrgNsXzHM78Lbw/hXANzwYD/hx4FUW6ABeAjy4NKUfp8IAXeHAZhrvRkTi5JhBH/a5vwv4KrALuNXdd5rZDWZ2WTjbJ4EBM9sD/C4wdwnmjUAncD/BDuPv3f2+JV6H9hT6KTSD8W50QlZE4iTVzkzuvg3YtmDa9fPuVwgupVy4XHGx6Ssi30+uvhNA492ISKzE45uxAIUB0tUJQCNYiki8xCjo+0g2SmSoq+tGRGIlRkEffDu2l6K6bkQkVuIT9HPfjk0W1XUjIrESn6APBzYbzpWZmFXQi0h8xCjow6GKcxXGFfQiEiPxCfqw62ZdpsToTHWFixEROXXiE/SFuREsSxwqqkUvIvERn6BPZSHTyWCiyOhMlWCEBhGR6ItP0APk++mzGWrNFtOVxkpXIyJySsQr6Av9dPkMgPrpRSQ2Yhf0HY1gYLNDRQW9iMRDzIJ+gGx9ElCLXkTiI15Bn+8nFQ5spha9iMRFvIK+0E+iOk0m0VKLXkRiI2ZBH3w79qyOmlr0IhIb8Qr6fB8AmwoVtehFJDbiFfRhi35DrqJvx4pIbMQs6INhENZrvBsRiZF4BX04sNmqdIlDxSqtloZBEJHoayvozexSM3vIzPaY2bWLPJ81s38Kn/+emW2c99z5ZvYdM9tpZj8ys9zSlX+cwq6bwcQsjZYzVdYvTYlI9B0z6M0sCdwIbAU2A282s80LZnsHMOHuzwE+AnwoXDYF3AL8prs/D3gFsHLpmilAKkcf4TAIuvJGRGKgnRb9xcAed3/E3WvA54DLF8xzOfDp8P5twKvNzIDXAPe5+w8B3H3M3ZtLU/oJKgzQ7eEwCOqnF5EYaCfo1wN75z0eCactOo+7N4ApYAA4B3Az+6qZ3WNmv7fYG5jZ1Wa2w8x2jI6OHu86HJ+utXRWDwBq0YtIPLQT9LbItIVnMY82Twp4OfBr4b9vNLNXP21G95vcfYu7bxkaGmqjpJPQdybZ4gig8W5EJB7aCfoRYMO8x8PAvqPNE/bL9wDj4fRvufshdy8B24ALT7bok9K3kcT0CPmkq0UvIrHQTtBvB842s01mlgGuAm5fMM/twNvC+1cA3/DgJ5y+CpxvZoVwB/BzwANLU/oJ6j0TazU4t2OGQzP60pSIRF/qWDO4e8PM3kUQ2kngZnffaWY3ADvc/Xbgk8A/mtkegpb8VeGyE2b2YYKdhQPb3P3Ly7Qu7ek7E4Bzc+PsVYteRGLgmEEP4O7bCLpd5k+7ft79CnDlUZa9heASy9NDbxD0z0mP8QP10YtIDMTrm7EAPcNgCc5IHFIfvYjEQvyCPpmG7mHW+gHGilWaGgZBRCIufkEP0Hcmg40naTlMlHRCVkSiLbZB311+AtC19CISffEM+t6N5KqjZNEvTYlI9MUz6MNLLIdtVC16EYm8eAZ9eInlBjuoFr2IRF48gz5s0W9KHlKLXkQiL55B37kaUjnOyY7rt2NFJPLiGfRm0Hsmm5KjPDFZXulqRESWVTyDHqDvTM6wUR7cP00w/pqISDTFN+h7gy9NTVca7JuqrHQ1IiLLJr5B33cmmcYM3RR5YN/0SlcjIrJs4hv0hy+xHGXXfgW9iERXfIO+byMAF3ZPKehFJNJiHPRBi/6CTgW9iERbfIM+1wO5Xs5Oj/GT8RKz1cZKVyQisiziG/QA/WexsbITd+fBJ2dWuhoRkWUR76Df8ht0T+5ia+L76r4RkchqK+jN7FIze8jM9pjZtYs8nzWzfwqf/56ZbVzw/BlmVjSza5am7CVywVvwoXN5X+ZWHto3vtLViIgsi2MGvZklgRuBrcBm4M1mtnnBbO8AJtz9OcBHgA8teP4jwFdOvtwllkhiP/9+NrKf9Y9+fqWrERFZFu206C8G9rj7I+5eAz4HXL5gnsuBT4f3bwNebWYGYGZvAB4Bdi5NyUvsnEv5SecLuGL6FloV9dOLSPS0E/Trgb3zHo+E0xadx90bwBQwYGYdwPuADzzTG5jZ1Wa2w8x2jI6Otlv70jBj9/nXMGhTTN3556f2vUVEToF2gt4WmbZwFLCjzfMB4CPuXnymN3D3m9x9i7tvGRoaaqOkpbVq8yXc3nwpfds/At//xCl/fxGR5ZRqY54RYMO8x8PAvqPMM2JmKaAHGAdeDFxhZn8C9AItM6u4+1+fdOVL6JzVXfxq8zfZPJjmOduugeo0/Ox7VrosEZEl0U7QbwfONrNNwBPAVcBbFsxzO/A24DvAFcA3PBj792fnZjCzPwCKp1vIA+TSSYYH+/jDwrV8ang1ducNUJmGn/+DYOx6EZFnsWN23YR97u8CvgrsAm51951mdoOZXRbO9kmCPvk9wO8CT7sE83S39by1fOvhSf608Lv4i34D/vOjcPu7oKlvzIrIs1s7LXrcfRuwbcG06+fdrwBXHuM1/uAE6jtlfvvVZzM6U+Vj33qUxCveyXt+bgj71odg9hBc8feQKax0iSIiJ6StoI+DRML4ozc8H3fnr7/5MP7KX+aa16/Gvvwe+MSr4AVXwU+/HgbPXulSRUSOS7yHQFggkTD+7xvP46qLNnDjXQ/z3se2UL/yFkim4evvh7/eAh/7Gbjv89BqrnS5IiJtUYt+gUTC+ONfPo/V3Tn+4s7d7J8a5GNv+wY91f3w0Ffg7k/BF/87fOuD8PLfgXN/KRgJU0TkNGWn2w9jb9myxXfs2LHSZQBw290jXPuF+zhjoMAfv/E8XnzWALRa8OC/wrf+BA7cD4k0bLoEznkt9J8FXWuhZz3k+1a6fBGJETO72923LPqcgv6ZfefhMa75/A95YrLMlS8a5rrXnUt/RyYI/L3fg4e+DLv+DSYefeqC3cOw7gJYdW5wQnf8EZgaCX7ZangLrH/RvJ2BQToP2U7IdkOuFxILetUaNfAWpHOnYrVF5FlGQX+SSrUGf/WNPXzi24/gwKquLGt6cmwa6OB1563l584ZJD27H6aegJl9MPETePI+2HcvjD8M+f6gtd+9DsYehtFdQWgfTaYLVj8P1jwfGhXYfx8c3AWtOnQMQff64N90DlI5SGYgkYREKrylIZkKps/dzKA6A+VJaJSD1+jbCL1nBDuXdCF4vVYTWg1oVKEyCaUxKI1DpiN4z46hYPrYw8HOrWstPHcr9AwHtbtD8SCUJ4KdV6YDsl2Qyp6KTSUSWwr6JfLjAzP86w/3sW+ywpPTZXbtn2F8tsZAR4bXPn8N63py9OTTdOfT9BUy9Hdk6MsZq3s7SSXntdCrxaDbpzYLeDBYRL0UBHF1OgjRA/fDgZ3BieA158PaF0CmE6ZHgiOD0lgQxo1K8G+rCd6EZj0I6mYdmjWeMlqFJYLzCakcFA88886mHZY48hprXxAcoTx5P5QOPX3edCE4Usl2cnjEDDOwZHj0YkfqNgt2ij3D0LMhXK4rWNaSwftaIth5ZDqCf4sHYfxRmHgMajPB9x+ateA1W42gzkY1vJWD11wbfq6da6BWDD772UMw+ThM7Q0+0596VdAtN7cjW8hdX6qT04KCfpnUmy2+/eNRvnjPE3zzoYPM1ha/EieVMIb78mzoL5BNJWg5uDtNh1bLabacVNJIJxNkkgmy6QS5VJJ8Jrh1ZlN0ZlPkM0ly6SS5VAIHZqsNitUGBqzpybO2J0dvIU2p1mS22qDZcnpzCQZy0JNNkMh2HukSatSCMJt8PNjh1MvBziaRDI8QUpDvhcJAEOD1chCms6OQ64b+nwpCeOJRePDLwYnqRhlWnxcciXQMHXnN6nRwJFGeDAJ1jreeeps7IvEmTO8P6iseOL6Nki4EO7O5o5pEOlgnS0IqA6l8sGOYPQgHHwyOkp62wXJBsDdrwecDwfrmuoPlE8ngsygegMpU8Bl1rYWOgeCzLI0H65zrhe610LUumCfXE+ywpvbCkz8KduTNWlBzphD8m8oG729JgkaABzv7XE9wy/dB56rg802mg6PIqZFgfeZ2/K1mUGv4c5l0DEJhMHhcmw2OtsoTQe2VyaDh0TF45AgvkQy3XTnYHulCcHSWygbvmUgH71MJt2l1GmqlYFu7B+uY6w52wslwmVYDpp8I6q3NBl2aa86DwXOCz6A2GzR0ZkeDW3kiqL1rDXSuPrJDT6aDektjwTyWOFJfphAcnWY6g7/F2UPBdmrWguXThfAIeN7RbqYzeC6ROrKzr879OxN8pvm+4PPJ9wXrN3fEO/l40CU7PRJs/4GzYeCs4PMvTwafj3v4fyodNmrCv8V0LvicMl3B3/vc/Ilk0K17AhT0p0i10WS63GCqXGOiVGditsahYo29EyUeHysxMlGi0fKgIYuRSBhJg4QZTXfqzRa1Rotqo0W51qRcb1KuNWm0Tn4bmUFnNkVXNkUhmzr8XvWm051L0VtI05NPY2Y0W07LHXdwgn8r9Saz1SaztQaZVILuXDA/QLkWTC9kkmzoK7Chv0Ahk2SiVGeqXKNab5FJJYJbMkEqmSCTNFLJBAkj/BwMCz8LMyNhkEwYKRr0Jqv0Jsp0J6oUUkY+bWRTkGnVSbUqJJsVkp1DJAbOgs5V1JrOdKXOdLnOwZkq+6fK7J+qUK23yKYTZFNJao0W08Ui6bGH6G5N0d8/yKpVq+gbWIUXhkgmEzSbLWoHHiT36NfoPvRDslTJUiNtjnUOke5ZQyLfS216lNrkEzB7iES2i0z3AOlCL5Qn8Kl9+Mx+KE+QqM8C4Kk8tnozrH5+EDT12SM72/lhbQYYNKvBkByVKSiPh0dq82S7g/BP54NgtUQQUpWpIAwb5cX+Io7sDDKdQSAudiTW/l9YEKRmT92ZL5TvC3aWMwuHy3oWS6SC8F8K67fA/7jzhBZV0D+LuTvVRotitUG51qTaaFKpB90lXbmgpd90Z/9khX2TZaYrdQqZYHoyYUsLKY8AAAkDSURBVEyUaowVa0yUasxUgiOAUq1x+OghlTSmKw0mSzWmykHrNjkvbM0MIxgPqCObpJBJUWu2mC7XmSrXMaCQSVHIJClWG+wdL7F/uoI7pJNGbyFDNpWg1mhRC3cujaZTa55kt9EizILa290xZlMJBjoy1JrOoWL1hN4zlVj8/TqzKZotp1w/cpSXpEkXJYrWwYVnDvLqc1fRlUvzZLgjqjRawY7PjGqjyVS5znS5wWy1Eez0601KtQbZxiwDNkWGBoWhM3jepg389JouSrUmM5UGk+UaB6erHJypcmC6wvT0JH3M0MMslWSB55y5gQuecyZd+QzuTr3p7J0ose/AKNWxxzAgke0gnc2TTxkdVqMzUcUbNRr1GvV6lWQ6S1fvEL39q8h199G0LE2Hx8ZK/OePn+TAoTEKVOjJOBcOd/C89X2sHd7EWetX05tPs+uRn/Dkj3dQG90DqRyW6SCZ66JrYC2Da4YZGlrL2NiTjO57nJlDT1AsTlMqlahWyuQ7uxlatY7h9evJp5O0aiVatRKNcpF6eYpmeRpLZcn2rKFjYA2pdI56pUijWqJZK9Os12g2ajRrZRqVIs1KEVoNkrkuUoVusoVuOnsG6OkdoLNQoF4cozZzkMbsBA03mp6gZSlSA2fSufYcsr1ruGfXwzy0cweTIw+Ry+UYHFrN+jVr2DDQxbruNPlEK2i5t5p4q0mlPMvM1Diz05NYIkGhZ5CuviHy/euDI50ToKCXU6raaFJvOh2ZJHaU/mt3D48coBXe93B6qxVMa7nTaDkzlQYzlTozlWAnNVttUqo3w51Gi3qzRaPltFrB/IVMku58mu5cmsHOLGt7c6zpzpFPJ6k1W1TrLVJJozCvvplKnccOlTg4Uzl8RGNm9ObT9BYy5NNJpsp1JkrBTnNuRzdbazLQkWFtT57+jgyHilWemCzz5FSFTCpBIZMM6skF527y6SQ/eHyCr+86yAPh7xQnDIa6snRkUuF6QyaVCM735FJ0ZFPk02FXXjp5eAc/U2mw/ScT3POTCYrVxuHX6s6nWdWVZXV3jlVdOdb35Rnuy9OdS7H9sQm+/eNRdh98aqu7kEmyabCDTYMdJMwoVhsUKw0qjeBzrjVapJMJCtkkHZkUxWqDkYny03aQuXSCF28a4JJzhhjqyvL9R8f47iPj7Dm4eCt/fW+eRqt1uLtxsX10MmEMdWZZ1Z2lt5Bh73iJRw/NHs+f5DNKJ41UIvGUnfKJ6MymeMlZ/YzP1nhg//ThBhnA6u4s6WSC2Wrw93u0hs4Lz+jlS7/1shN6fwW9yGnowHSFljtDndmnnqw/Ts2WM1as0pFNPWXn9UwmSzVqzRYJC7rNegvptpZbqFxrMlOpk0gYCTM6sykyqaevy3SlzsMHi+w+WGRitsbz1vVw/oYeunPpw/M0mi32TVZ4bGyW/VNlVnUHV7at78uTXvD5zFTq7No/E+6AjHQqEXRN5lJ05dLUGi0OzlQ4OF2l1mgdPr+VTSXIpRNkkklymaALMptKYPOOosZnjxwRTZZqFDIpOrLBTjaTSpBOJjBgqlzn0GyNmUqdC4Z72bKx//C6N1vOI6NF9hws8sihWR49NEur5cE2yibpL2RY1Z1lVVcOd4JaZ6p05VL82ovPPO7tAAp6EZHIe6ag11g3IiIRp6AXEYk4Bb2ISMQp6EVEIk5BLyIScQp6EZGIU9CLiEScgl5EJOJOuy9Mmdko8JOTeIlB4GRGZ3o2iuM6QzzXO47rDPFc7+Nd5zPdfWixJ067oD9ZZrbjaN8Oi6o4rjPEc73juM4Qz/VeynVW142ISMQp6EVEIi6KQX/TShewAuK4zhDP9Y7jOkM813vJ1jlyffQiIvJUUWzRi4jIPAp6EZGIi0zQm9mlZvaQme0xs2tXup7lYmYbzOwuM9tlZjvN7N3h9H4z+5qZ7Q7/7VvpWpeamSXN7Adm9m/h401m9r1wnf/JzDIrXeNSM7NeM7vNzB4Mt/lLo76tzex3wr/t+83ss2aWi+K2NrObzeygmd0/b9qi29YCfxnm231mduHxvFckgt7MksCNwFZgM/BmM9u8slUtmwbwHnc/F3gJ8D/Ddb0WuNPdzwbuDB9HzbuBXfMefwj4SLjOE8A7VqSq5fUXwL+7+08DLyBY/8huazNbD/wvYIu7Px9IAlcRzW39KeDSBdOOtm23AmeHt6uBjx/PG0Ui6IGLgT3u/oi714DPAZevcE3Lwt33u/s94f0Zgv/46wnW99PhbJ8G3rAyFS4PMxsGXg/8XfjYgFcBt4WzRHGdu4FLgE8CuHvN3SeJ+LYGUkDezFJAAdhPBLe1u38bGF8w+Wjb9nLgHzzwXaDXzNa2+15RCfr1wN55j0fCaZFmZhuBFwLfA1a7+34IdgbAqpWrbFl8FPg9oBU+HgAm3b0RPo7iNj8LGAX+Puyy+jsz6yDC29rdnwD+DHicIOCngLuJ/raec7Rte1IZF5WgX+zn6yN93aiZdQJfAH7b3adXup7lZGa/CBx097vnT15k1qht8xRwIfBxd38hMEuEumkWE/ZJXw5sAtYBHQTdFgtFbVsfy0n9vUcl6EeADfMeDwP7VqiWZWdmaYKQ/3/u/sVw8oG5Q7nw34MrVd8yeBlwmZk9RtAt9yqCFn5veHgP0dzmI8CIu38vfHwbQfBHeVv/PPCou4+6ex34IvAzRH9bzznatj2pjItK0G8Hzg7PzGcITt7cvsI1LYuwb/qTwC53//C8p24H3hbefxvwL6e6tuXi7te5+7C7byTYtt9w918D7gKuCGeL1DoDuPuTwF4ze2446dXAA0R4WxN02bzEzArh3/rcOkd6W89ztG17O/Dr4dU3LwGm5rp42uLukbgBrwN+DDwM/O+VrmcZ1/PlBIds9wH3hrfXEfRZ3wnsDv/tX+lal2n9XwH8W3j/LOD7wB7g80B2petbhvW9ANgRbu9/Bvqivq2BDwAPAvcD/whko7itgc8SnIeoE7TY33G0bUvQdXNjmG8/Irgqqe330hAIIiIRF5WuGxEROQoFvYhIxCnoRUQiTkEvIhJxCnoRkYhT0IuIRJyCXkQk4v4/o42Mnvf45DIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(300, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=100, batch_size=84, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "#pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 2.502\n"
     ]
    }
   ],
   "source": [
    "# make a prediction using 20% of the 5 meter groups \n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = concatenate((yhat, test_X[:, 1:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 5.758\n"
     ]
    }
   ],
   "source": [
    "# make a prediction using all indivdual meter data\n",
    "# load dataset\n",
    "dataset = read_csv('CharlestownAll.csv', header=0, sep='[,]', parse_dates=True, squeeze=True, dayfirst=True, engine='python') \n",
    "#dataset = dataset.loc[dataset['MeterNo'] == 6]\n",
    "dataset.drop(dataset.columns[[0,2,5,8]], axis = 1, inplace = True)\n",
    "dataset = dataset[['kWh', 'Temp', 'Area_m2', 'Month', 'Weekday', 'Holiday']]\n",
    "values = dataset.values\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "#savetxt('CharlestownValues.csv', values, delimiter=',')\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, 1, 1)\n",
    "# drop columns we don't want to predict\n",
    "reframed.drop(reframed.columns[[7,8,9,10,11]], axis=1, inplace=True)\n",
    "#print(reframed.head())\n",
    "#shuffle rows\n",
    "reframed=reframed.sample(frac=1).reset_index(drop=True)\n",
    "#print(reframed.head())\n",
    "values = reframed.values\n",
    "# split into input and outputs\n",
    "test_X, test_y = values[:, :-1], values[:, -1]\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "#print(test_X.shape, test_y.shape)\n",
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = concatenate((yhat, test_X[:, 1:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MeterNo 1 - Test RMSE: 3.032\n",
      "MeterNo 2 - Test RMSE: 6.253\n",
      "MeterNo 3 - Test RMSE: 6.476\n",
      "MeterNo 4 - Test RMSE: 3.620\n",
      "MeterNo 5 - Test RMSE: 2.756\n",
      "MeterNo 6 - Test RMSE: 9.948\n",
      "MeterNo 7 - Test RMSE: 4.671\n",
      "MeterNo 8 - Test RMSE: 4.169\n",
      "MeterNo 9 - Test RMSE: 2.246\n",
      "MeterNo 10 - Test RMSE: 5.757\n",
      "MeterNo 11 - Test RMSE: 5.158\n",
      "MeterNo 12 - Test RMSE: 5.963\n",
      "MeterNo 13 - Test RMSE: 4.998\n",
      "MeterNo 14 - Test RMSE: 3.966\n",
      "MeterNo 15 - Test RMSE: 9.150\n",
      "MeterNo 16 - Test RMSE: 6.943\n",
      "MeterNo 17 - Test RMSE: 4.341\n",
      "MeterNo 18 - Test RMSE: 5.859\n",
      "MeterNo 19 - Test RMSE: 4.570\n",
      "MeterNo 20 - Test RMSE: 4.542\n",
      "MeterNo 21 - Test RMSE: 4.566\n",
      "MeterNo 22 - Test RMSE: 10.712\n",
      "MeterNo 23 - Test RMSE: 9.738\n",
      "MeterNo 24 - Test RMSE: 6.435\n",
      "MeterNo 25 - Test RMSE: 7.646\n",
      "MeterNo 26 - Test RMSE: 4.836\n",
      "MeterNo 27 - Test RMSE: 4.661\n",
      "MeterNo 28 - Test RMSE: 5.250\n",
      "MeterNo 29 - Test RMSE: 5.658\n",
      "MeterNo 30 - Test RMSE: 4.338\n",
      "MeterNo 31 - Test RMSE: 2.959\n",
      "MeterNo 32 - Test RMSE: 3.079\n",
      "MeterNo 33 - Test RMSE: 3.570\n",
      "MeterNo 34 - Test RMSE: 2.548\n",
      "MeterNo 35 - Test RMSE: 1.862\n",
      "MeterNo 36 - Test RMSE: 7.699\n",
      "MeterNo 37 - Test RMSE: 3.484\n",
      "MeterNo 38 - Test RMSE: 6.604\n",
      "MeterNo 39 - Test RMSE: 5.486\n",
      "MeterNo 40 - Test RMSE: 6.812\n",
      "MeterNo 41 - Test RMSE: 5.200\n",
      "MeterNo 42 - Test RMSE: 6.947\n",
      "MeterNo 43 - Test RMSE: 4.767\n",
      "MeterNo 44 - Test RMSE: 7.482\n",
      "MeterNo 45 - Test RMSE: 5.225\n",
      "MeterNo 46 - Test RMSE: 4.439\n",
      "MeterNo 47 - Test RMSE: 5.662\n",
      "MeterNo 48 - Test RMSE: 4.220\n",
      "MeterNo 49 - Test RMSE: 5.317\n",
      "MeterNo 50 - Test RMSE: 3.692\n",
      "MeterNo 51 - Test RMSE: 3.000\n",
      "MeterNo 52 - Test RMSE: 3.393\n",
      "MeterNo 53 - Test RMSE: 4.225\n",
      "MeterNo 54 - Test RMSE: 5.516\n",
      "MeterNo 55 - Test RMSE: 1.069\n",
      "MeterNo 56 - Test RMSE: 2.736\n",
      "MeterNo 57 - Test RMSE: 6.052\n",
      "MeterNo 58 - Test RMSE: 9.140\n",
      "MeterNo 59 - Test RMSE: 6.369\n",
      "MeterNo 60 - Test RMSE: 6.407\n",
      "MeterNo 61 - Test RMSE: 7.672\n",
      "MeterNo 62 - Test RMSE: 5.997\n",
      "MeterNo 63 - Test RMSE: 8.177\n",
      "MeterNo 64 - Test RMSE: 4.436\n",
      "MeterNo 65 - Test RMSE: 6.576\n",
      "MeterNo 66 - Test RMSE: 7.107\n",
      "MeterNo 67 - Test RMSE: 3.287\n",
      "MeterNo 68 - Test RMSE: 0.033\n",
      "MeterNo 69 - Test RMSE: 6.579\n",
      "MeterNo 70 - Test RMSE: 1.847\n",
      "MeterNo 71 - Test RMSE: 3.546\n",
      "MeterNo 72 - Test RMSE: 5.238\n",
      "MeterNo 73 - Test RMSE: 4.000\n",
      "MeterNo 74 - Test RMSE: 6.335\n",
      "MeterNo 75 - Test RMSE: 5.652\n",
      "MeterNo 76 - Test RMSE: 1.809\n",
      "MeterNo 77 - Test RMSE: 5.015\n",
      "MeterNo 78 - Test RMSE: 4.466\n",
      "MeterNo 79 - Test RMSE: 5.613\n",
      "MeterNo 80 - Test RMSE: 3.820\n",
      "MeterNo 81 - Test RMSE: 4.639\n",
      "MeterNo 82 - Test RMSE: 5.818\n",
      "MeterNo 83 - Test RMSE: 11.244\n",
      "MeterNo 84 - Test RMSE: 4.444\n",
      "MeterNo 85 - Test RMSE: 4.452\n",
      "MeterNo 86 - Test RMSE: 5.634\n",
      "MeterNo 87 - Test RMSE: 3.415\n",
      "MeterNo 88 - Test RMSE: 3.256\n",
      "MeterNo 89 - Test RMSE: 5.445\n",
      "MeterNo 90 - Test RMSE: 8.554\n",
      "MeterNo 91 - Test RMSE: 3.925\n",
      "MeterNo 92 - Test RMSE: 4.114\n",
      "MeterNo 93 - Test RMSE: 4.671\n",
      "MeterNo 94 - Test RMSE: 4.435\n",
      "MeterNo 95 - Test RMSE: 1.697\n",
      "MeterNo 96 - Test RMSE: 3.656\n",
      "MeterNo 97 - Test RMSE: 5.677\n",
      "MeterNo 98 - Test RMSE: 4.360\n",
      "MeterNo 99 - Test RMSE: 3.356\n",
      "MeterNo 100 - Test RMSE: 6.388\n",
      "MeterNo 101 - Test RMSE: 6.550\n",
      "MeterNo 102 - Test RMSE: 6.136\n",
      "MeterNo 103 - Test RMSE: 5.736\n",
      "MeterNo 104 - Test RMSE: 5.109\n",
      "MeterNo 105 - Test RMSE: 6.711\n",
      "MeterNo 106 - Test RMSE: 6.330\n",
      "MeterNo 107 - Test RMSE: 5.111\n",
      "MeterNo 108 - Test RMSE: 5.350\n",
      "MeterNo 109 - Test RMSE: 8.337\n",
      "MeterNo 110 - Test RMSE: 2.336\n",
      "MeterNo 111 - Test RMSE: 4.832\n",
      "MeterNo 112 - Test RMSE: 3.912\n",
      "MeterNo 113 - Test RMSE: 2.695\n",
      "MeterNo 114 - Test RMSE: 6.776\n",
      "MeterNo 115 - Test RMSE: 5.434\n",
      "MeterNo 116 - Test RMSE: 7.791\n",
      "MeterNo 117 - Test RMSE: 6.545\n",
      "MeterNo 118 - Test RMSE: 2.883\n",
      "MeterNo 119 - Test RMSE: 4.776\n",
      "MeterNo 120 - Test RMSE: 3.585\n",
      "MeterNo 121 - Test RMSE: 7.140\n",
      "MeterNo 122 - Test RMSE: 4.424\n",
      "MeterNo 123 - Test RMSE: 4.447\n",
      "MeterNo 124 - Test RMSE: 5.560\n",
      "MeterNo 125 - Test RMSE: 4.613\n",
      "MeterNo 126 - Test RMSE: 4.339\n",
      "MeterNo 127 - Test RMSE: 3.799\n",
      "MeterNo 128 - Test RMSE: 2.131\n",
      "MeterNo 129 - Test RMSE: 3.735\n",
      "MeterNo 130 - Test RMSE: 4.460\n",
      "MeterNo 131 - Test RMSE: 3.209\n",
      "MeterNo 132 - Test RMSE: 4.435\n",
      "MeterNo 133 - Test RMSE: 5.965\n",
      "MeterNo 134 - Test RMSE: 3.561\n",
      "MeterNo 135 - Test RMSE: 6.902\n",
      "MeterNo 136 - Test RMSE: 6.389\n",
      "MeterNo 137 - Test RMSE: 5.959\n",
      "MeterNo 138 - Test RMSE: 10.159\n",
      "MeterNo 139 - Test RMSE: 5.375\n",
      "MeterNo 140 - Test RMSE: 2.821\n",
      "MeterNo 141 - Test RMSE: 11.769\n",
      "MeterNo 142 - Test RMSE: 5.818\n",
      "MeterNo 143 - Test RMSE: 4.889\n",
      "MeterNo 144 - Test RMSE: 4.499\n",
      "MeterNo 145 - Test RMSE: 3.644\n",
      "MeterNo 146 - Test RMSE: 2.657\n",
      "MeterNo 147 - Test RMSE: 3.615\n",
      "MeterNo 148 - Test RMSE: 3.859\n",
      "MeterNo 149 - Test RMSE: 4.539\n",
      "MeterNo 150 - Test RMSE: 7.043\n",
      "MeterNo 151 - Test RMSE: 2.997\n",
      "MeterNo 152 - Test RMSE: 6.457\n",
      "MeterNo 153 - Test RMSE: 3.846\n",
      "MeterNo 154 - Test RMSE: 9.662\n",
      "MeterNo 155 - Test RMSE: 6.787\n",
      "MeterNo 156 - Test RMSE: 5.479\n",
      "MeterNo 157 - Test RMSE: 5.093\n",
      "MeterNo 158 - Test RMSE: 4.446\n",
      "MeterNo 159 - Test RMSE: 3.364\n",
      "MeterNo 160 - Test RMSE: 7.963\n",
      "MeterNo 161 - Test RMSE: 2.643\n",
      "MeterNo 162 - Test RMSE: 7.085\n",
      "MeterNo 163 - Test RMSE: 7.447\n",
      "MeterNo 164 - Test RMSE: 3.441\n",
      "MeterNo 165 - Test RMSE: 3.986\n",
      "MeterNo 166 - Test RMSE: 7.685\n",
      "MeterNo 167 - Test RMSE: 4.058\n",
      "MeterNo 168 - Test RMSE: 4.123\n",
      "MeterNo 169 - Test RMSE: 8.806\n",
      "MeterNo 170 - Test RMSE: 4.924\n",
      "MeterNo 171 - Test RMSE: 3.119\n",
      "MeterNo 172 - Test RMSE: 3.164\n",
      "MeterNo 173 - Test RMSE: 7.223\n",
      "MeterNo 174 - Test RMSE: 6.425\n",
      "MeterNo 175 - Test RMSE: 4.058\n",
      "MeterNo 176 - Test RMSE: 5.021\n",
      "MeterNo 177 - Test RMSE: 2.478\n",
      "MeterNo 178 - Test RMSE: 4.045\n",
      "MeterNo 179 - Test RMSE: 3.150\n",
      "MeterNo 180 - Test RMSE: 9.323\n",
      "MeterNo 181 - Test RMSE: 6.736\n",
      "MeterNo 182 - Test RMSE: 4.568\n",
      "MeterNo 183 - Test RMSE: 4.578\n",
      "MeterNo 184 - Test RMSE: 4.475\n",
      "MeterNo 185 - Test RMSE: 6.255\n",
      "MeterNo 186 - Test RMSE: 4.562\n",
      "MeterNo 187 - Test RMSE: 6.171\n",
      "MeterNo 188 - Test RMSE: 5.732\n",
      "MeterNo 189 - Test RMSE: 9.369\n",
      "MeterNo 190 - Test RMSE: 6.722\n",
      "MeterNo 191 - Test RMSE: 3.307\n",
      "MeterNo 192 - Test RMSE: 4.364\n",
      "MeterNo 193 - Test RMSE: 6.596\n",
      "MeterNo 194 - Test RMSE: 3.295\n",
      "MeterNo 195 - Test RMSE: 3.950\n",
      "MeterNo 196 - Test RMSE: 3.446\n",
      "MeterNo 197 - Test RMSE: 5.312\n",
      "MeterNo 198 - Test RMSE: 4.016\n",
      "MeterNo 199 - Test RMSE: 2.706\n",
      "MeterNo 200 - Test RMSE: 2.654\n",
      "MeterNo 201 - Test RMSE: 4.751\n",
      "MeterNo 202 - Test RMSE: 5.430\n",
      "MeterNo 203 - Test RMSE: 3.473\n",
      "MeterNo 204 - Test RMSE: 3.993\n",
      "MeterNo 205 - Test RMSE: 8.588\n",
      "MeterNo 206 - Test RMSE: 4.727\n",
      "MeterNo 207 - Test RMSE: 3.407\n",
      "MeterNo 208 - Test RMSE: 8.772\n",
      "MeterNo 209 - Test RMSE: 3.632\n",
      "MeterNo 210 - Test RMSE: 5.184\n",
      "MeterNo 211 - Test RMSE: 5.109\n",
      "MeterNo 212 - Test RMSE: 5.297\n",
      "MeterNo 213 - Test RMSE: 7.126\n",
      "MeterNo 214 - Test RMSE: 0.033\n",
      "MeterNo 215 - Test RMSE: 1.210\n",
      "MeterNo 216 - Test RMSE: 6.406\n",
      "MeterNo 217 - Test RMSE: 5.396\n",
      "MeterNo 218 - Test RMSE: 3.061\n",
      "MeterNo 219 - Test RMSE: 3.702\n",
      "MeterNo 220 - Test RMSE: 4.130\n",
      "MeterNo 221 - Test RMSE: 4.778\n",
      "MeterNo 222 - Test RMSE: 4.958\n",
      "MeterNo 223 - Test RMSE: 5.048\n",
      "MeterNo 224 - Test RMSE: 5.543\n",
      "MeterNo 225 - Test RMSE: 5.714\n",
      "MeterNo 226 - Test RMSE: 8.723\n",
      "MeterNo 227 - Test RMSE: 9.812\n",
      "MeterNo 228 - Test RMSE: 4.180\n",
      "MeterNo 229 - Test RMSE: 6.674\n",
      "MeterNo 230 - Test RMSE: 4.219\n",
      "MeterNo 231 - Test RMSE: 6.875\n",
      "MeterNo 232 - Test RMSE: 2.797\n",
      "MeterNo 233 - Test RMSE: 3.382\n",
      "MeterNo 234 - Test RMSE: 5.783\n",
      "MeterNo 235 - Test RMSE: 5.588\n",
      "MeterNo 236 - Test RMSE: 3.956\n",
      "MeterNo 237 - Test RMSE: 6.365\n",
      "MeterNo 238 - Test RMSE: 5.692\n",
      "MeterNo 239 - Test RMSE: 6.199\n",
      "MeterNo 240 - Test RMSE: 3.358\n",
      "MeterNo 241 - Test RMSE: 10.212\n",
      "MeterNo 242 - Test RMSE: 12.976\n",
      "MeterNo 243 - Test RMSE: 5.107\n",
      "MeterNo 244 - Test RMSE: 4.340\n",
      "MeterNo 245 - Test RMSE: 3.433\n",
      "MeterNo 246 - Test RMSE: 5.325\n",
      "MeterNo 247 - Test RMSE: 6.064\n",
      "MeterNo 248 - Test RMSE: 0.033\n",
      "MeterNo 249 - Test RMSE: 3.126\n",
      "MeterNo 250 - Test RMSE: 3.698\n",
      "MeterNo 251 - Test RMSE: 4.778\n",
      "MeterNo 252 - Test RMSE: 3.133\n",
      "MeterNo 253 - Test RMSE: 6.057\n",
      "MeterNo 254 - Test RMSE: 9.116\n",
      "MeterNo 255 - Test RMSE: 3.440\n",
      "MeterNo 256 - Test RMSE: 5.897\n",
      "MeterNo 257 - Test RMSE: 5.344\n",
      "MeterNo 258 - Test RMSE: 5.451\n",
      "MeterNo 259 - Test RMSE: 2.859\n",
      "MeterNo 260 - Test RMSE: 3.635\n",
      "MeterNo 261 - Test RMSE: 5.452\n",
      "MeterNo 262 - Test RMSE: 7.315\n",
      "MeterNo 263 - Test RMSE: 5.074\n",
      "MeterNo 264 - Test RMSE: 4.775\n",
      "MeterNo 265 - Test RMSE: 4.624\n",
      "MeterNo 266 - Test RMSE: 7.206\n",
      "MeterNo 267 - Test RMSE: 5.802\n",
      "MeterNo 268 - Test RMSE: 8.550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MeterNo 269 - Test RMSE: 6.245\n",
      "MeterNo 270 - Test RMSE: 5.901\n",
      "MeterNo 271 - Test RMSE: 7.238\n",
      "MeterNo 272 - Test RMSE: 7.656\n",
      "MeterNo 273 - Test RMSE: 4.507\n",
      "MeterNo 274 - Test RMSE: 5.185\n",
      "MeterNo 275 - Test RMSE: 5.584\n",
      "MeterNo 276 - Test RMSE: 6.893\n",
      "MeterNo 277 - Test RMSE: 5.742\n",
      "MeterNo 278 - Test RMSE: 5.281\n",
      "MeterNo 279 - Test RMSE: 5.388\n",
      "MeterNo 280 - Test RMSE: 11.455\n",
      "MeterNo 281 - Test RMSE: 9.709\n",
      "MeterNo 282 - Test RMSE: 9.439\n",
      "MeterNo 283 - Test RMSE: 7.276\n",
      "MeterNo 284 - Test RMSE: 7.103\n",
      "MeterNo 285 - Test RMSE: 7.668\n"
     ]
    }
   ],
   "source": [
    "# make a prediction using data from a single meter\n",
    "# load dataset\n",
    "dataset = read_csv('CharlestownAll.csv', header=0, sep='[,]', parse_dates=True, squeeze=True, dayfirst=True, engine='python') \n",
    "#dataset = dataset.loc[dataset['MeterNo'] <3]\n",
    "meter_ids = unique(dataset['MeterNo'])\n",
    "#print(meter_ids)\n",
    "results = dict()\n",
    "results_df = []\n",
    "for m in meter_ids:\n",
    "    dataset = read_csv('CharlestownAll.csv', header=0, sep='[,]', parse_dates=True, squeeze=True, dayfirst=True, engine='python') \n",
    "    dataset = dataset.loc[dataset['MeterNo'] == m]\n",
    "    dataset.drop(dataset.columns[[0,2,5,8]], axis = 1, inplace = True)\n",
    "    dataset = dataset[['kWh', 'Temp', 'Area_m2', 'Month', 'Weekday', 'Holiday']]\n",
    "    values = dataset.values\n",
    "    # ensure all data is float\n",
    "    values = values.astype('float32')\n",
    "    #savetxt('CharlestownValues.csv', values, delimiter=',')\n",
    "    # normalize features\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled = scaler.fit_transform(values)\n",
    "    # frame as supervised learning\n",
    "    reframed = series_to_supervised(scaled, 1, 1)\n",
    "    # drop columns we don't want to predict\n",
    "    reframed.drop(reframed.columns[[7,8,9,10,11]], axis=1, inplace=True)\n",
    "    #print(reframed.head())\n",
    "    #shuffle rows\n",
    "    reframed=reframed.sample(frac=1).reset_index(drop=True)\n",
    "    #print(reframed.head())\n",
    "    values = reframed.values\n",
    "    # split into input and outputs\n",
    "    test_X, test_y = values[:, :-1], values[:, -1]\n",
    "    # reshape input to be 3D [samples, timesteps, features]\n",
    "    test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "    #print(test_X.shape, test_y.shape)\n",
    "    # make a prediction\n",
    "    yhat = model.predict(test_X)\n",
    "    test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "    # invert scaling for forecast\n",
    "    inv_yhat = concatenate((yhat, test_X[:, 1:]), axis=1)\n",
    "    inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "    inv_yhat = inv_yhat[:,0]\n",
    "    # invert scaling for actual\n",
    "    test_y = test_y.reshape((len(test_y), 1))\n",
    "    inv_y = concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "    inv_y = scaler.inverse_transform(inv_y)\n",
    "    inv_y = inv_y[:,0]\n",
    "    # calculate RMSE\n",
    "    rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "    print('MeterNo %s - Test RMSE: %.3f' % (m, rmse))\n",
    "    results[m] = rmse #dict\n",
    "    results_df.append([m, rmse]) #array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     MeterID      RMSE\n",
      "0          1  3.032319\n",
      "1          2  6.252751\n",
      "2          3  6.475554\n",
      "3          4  3.619977\n",
      "4          5  2.756373\n",
      "..       ...       ...\n",
      "280      281  9.709321\n",
      "281      282  9.438989\n",
      "282      283  7.275848\n",
      "283      284  7.102911\n",
      "284      285  7.667659\n",
      "\n",
      "[285 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "results_df=DataFrame(results_df)\n",
    "results_df.columns = ['MeterID', 'RMSE']\n",
    "print(results_df)\n",
    "#type(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('CharlestownGroupByRSMEs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.drop(results_df.columns[[0]], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RMSE    0.0332\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.min()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RMSE    12.975556\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RMSE    5.261634\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
